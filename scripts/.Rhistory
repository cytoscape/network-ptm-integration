} else {
first_attribute_values <- NA
}
}
# Create a separate row for each value in first_attr$value[[1]]
for (value in first_attribute_values) {
results[[length(results) + 1]] <- data.frame(
predicate = predicate,
subject = subject,
object = object,
attribute_value = value,
stringsAsFactors = FALSE
)
}
}
}
}
# Combine the list into a single dataframe
edges_df <- bind_rows(results)
# Display the dataframe
head(edges_df)
# Create subset_edge_df with attribute_values starting with "https"
fig_df <- edges_df %>%
filter(grepl("^https", attribute_value))
# URL of the JSON file
url <- "https://bte.transltr.io/v1/asyncquery_response/imQs8peZu0"
# Retrieve JSON file from the URL
response <- GET(url)
json_data <- content(response, as = "text")
parsed_data <- fromJSON(json_data, flatten = TRUE)
# Extract relevant entries
edges <- parsed_data$message$knowledge_graph$edges
# Initialize an empty list to store the results
results <- list()
# Iterate over each edge by index
for (i in seq_along(edges)) {
edge <- edges[[i]]
predicate <- edge$predicate
subject <- edge$subject
object <- edge$object
# Only include cases where predicate is "biolink:occurs_together_in_literature_with"
if (predicate == "biolink:occurs_together_in_literature_with") {
# Check if attributes exist and if the first attribute has a value
if (!is.null(edge$attributes) && length(edge$attributes) > 0) {
first_attr <- edge$attributes[1,]
if (!is.null(first_attr$value)) {
if (is.atomic(first_attr$value)) {
first_attribute_values <- list(first_attr$value)
} else if (is.list(first_attr$value) && length(first_attr$value) > 0) {
first_attribute_values <- first_attr$value[[1]]
} else {
first_attribute_values <- NA
}
}
# Create a separate row for each value in first_attr$value[[1]]
for (value in first_attribute_values) {
results[[length(results) + 1]] <- data.frame(
predicate = predicate,
subject = subject,
object = object,
attribute_value = value,
stringsAsFactors = FALSE
)
}
}
}
}
# Combine the list into a single dataframe
edges_df <- bind_rows(results)
# Display the dataframe
head(edges_df)
# Create subset_edge_df with attribute_values starting with "https"
fig_df <- edges_df %>%
filter(grepl("^https", attribute_value))
# Display the final dataframe
head(fig_df)
# Count the unique values in attribute_value_2
count_fig_df <- fig_df %>%
group_by(attribute_value) %>%
summarise(count = n()) %>%
arrange(desc(count)) %>%
as.data.frame()
# Display the count dataframe
head(count_fig_df)
# Create subset_edge_df with attribute_values starting with "https"
pmc_df <- edges_df %>%
filter(grepl("^PMCID", attribute_value))
# Display the final dataframe
head(pmc_df)
# Count the unique values in attribute_value_2
count_pmc_df <- pmc_df %>%
group_by(attribute_value) %>%
summarise(count = n()) %>%
arrange(desc(count)) %>%
as.data.frame()
# Display the count dataframe
head(count_pmc_df)
# URL of the JSON file
url <- "https://bte.transltr.io/v1/asyncquery_response/VbcxnE73jg"
# Retrieve JSON file from the URL
response <- GET(url)
json_data <- content(response, as = "text")
parsed_data <- fromJSON(json_data, flatten = TRUE)
# Extract relevant entries
edges <- parsed_data$message$knowledge_graph$edges
# Initialize an empty list to store the results
results <- list()
# Iterate over each edge by index
for (i in seq_along(edges)) {
edge <- edges[[i]]
predicate <- edge$predicate
subject <- edge$subject
object <- edge$object
# Only include cases where predicate is "biolink:occurs_together_in_literature_with"
if (predicate == "biolink:occurs_together_in_literature_with") {
# Check if attributes exist and if the first attribute has a value
if (!is.null(edge$attributes) && length(edge$attributes) > 0) {
first_attr <- edge$attributes[1,]
if (!is.null(first_attr$value)) {
if (is.atomic(first_attr$value)) {
first_attribute_values <- list(first_attr$value)
} else if (is.list(first_attr$value) && length(first_attr$value) > 0) {
first_attribute_values <- first_attr$value[[1]]
} else {
first_attribute_values <- NA
}
}
# Create a separate row for each value in first_attr$value[[1]]
for (value in first_attribute_values) {
results[[length(results) + 1]] <- data.frame(
predicate = predicate,
subject = subject,
object = object,
attribute_value = value,
stringsAsFactors = FALSE
)
}
}
}
}
# Combine the list into a single dataframe
edges_df <- bind_rows(results)
# Display the dataframe
head(edges_df)
# Create subset_edge_df with attribute_values starting with "https"
fig_df <- edges_df %>%
filter(grepl("^https", attribute_value))
# Display the final dataframe
head(fig_df)
# Count the unique values in attribute_value_2
count_fig_df <- fig_df %>%
group_by(attribute_value) %>%
summarise(count = n()) %>%
arrange(desc(count)) %>%
as.data.frame()
# Display the count dataframe
head(count_fig_df)
# Create subset_edge_df with attribute_values starting with "https"
pmc_df <- edges_df %>%
filter(grepl("^PMCID", attribute_value))
# Display the final dataframe
head(pmc_df)
# Count the unique values in attribute_value_2
count_pmc_df <- pmc_df %>%
group_by(attribute_value) %>%
summarise(count = n()) %>%
arrange(desc(count)) %>%
as.data.frame()
# Display the count dataframe
head(count_pmc_df)
# URL of the JSON file
url <- "https://bte.test.transltr.io/v1/asyncquery_response/ptu7sLn50x"
# Retrieve JSON file from the URL
response <- GET(url)
json_data <- content(response, as = "text")
parsed_data <- fromJSON(json_data, flatten = TRUE)
# Extract relevant entries
edges <- parsed_data$message$knowledge_graph$edges
# Initialize an empty list to store the results
results <- list()
# Iterate over each edge by index
for (i in seq_along(edges)) {
edge <- edges[[i]]
predicate <- edge$predicate
subject <- edge$subject
object <- edge$object
# Only include cases where predicate is "biolink:occurs_together_in_literature_with"
if (predicate == "biolink:occurs_together_in_literature_with") {
# Check if attributes exist and if the first attribute has a value
if (!is.null(edge$attributes) && length(edge$attributes) > 0) {
first_attr <- edge$attributes[1,]
if (!is.null(first_attr$value)) {
if (is.atomic(first_attr$value)) {
first_attribute_values <- list(first_attr$value)
} else if (is.list(first_attr$value) && length(first_attr$value) > 0) {
first_attribute_values <- first_attr$value[[1]]
} else {
first_attribute_values <- NA
}
}
# Create a separate row for each value in first_attr$value[[1]]
for (value in first_attribute_values) {
results[[length(results) + 1]] <- data.frame(
predicate = predicate,
subject = subject,
object = object,
attribute_value = value,
stringsAsFactors = FALSE
)
}
}
}
}
# Combine the list into a single dataframe
edges_df <- bind_rows(results)
# Display the dataframe
head(edges_df)
# Create subset_edge_df with attribute_values starting with "https"
fig_df <- edges_df %>%
filter(grepl("^https", attribute_value))
# URL of the JSON file
url <- "https://bte.transltr.io/v1/asyncquery_response/bgYopZpv52"
# Retrieve JSON file from the URL
response <- GET(url)
json_data <- content(response, as = "text")
parsed_data <- fromJSON(json_data, flatten = TRUE)
# Extract relevant entries
edges <- parsed_data$message$knowledge_graph$edges
# Initialize an empty list to store the results
results <- list()
# Iterate over each edge by index
for (i in seq_along(edges)) {
edge <- edges[[i]]
predicate <- edge$predicate
subject <- edge$subject
object <- edge$object
# Only include cases where predicate is "biolink:occurs_together_in_literature_with"
if (predicate == "biolink:occurs_together_in_literature_with") {
# Check if attributes exist and if the first attribute has a value
if (!is.null(edge$attributes) && length(edge$attributes) > 0) {
first_attr <- edge$attributes[1,]
if (!is.null(first_attr$value)) {
if (is.atomic(first_attr$value)) {
first_attribute_values <- list(first_attr$value)
} else if (is.list(first_attr$value) && length(first_attr$value) > 0) {
first_attribute_values <- first_attr$value[[1]]
} else {
first_attribute_values <- NA
}
}
# Create a separate row for each value in first_attr$value[[1]]
for (value in first_attribute_values) {
results[[length(results) + 1]] <- data.frame(
predicate = predicate,
subject = subject,
object = object,
attribute_value = value,
stringsAsFactors = FALSE
)
}
}
}
}
# Combine the list into a single dataframe
edges_df <- bind_rows(results)
# Display the dataframe
head(edges_df)
# Create subset_edge_df with attribute_values starting with "https"
fig_df <- edges_df %>%
filter(grepl("^https", attribute_value))
# Display the final dataframe
head(fig_df)
# Count the unique values in attribute_value_2
count_fig_df <- fig_df %>%
group_by(attribute_value) %>%
summarise(count = n()) %>%
arrange(desc(count)) %>%
as.data.frame()
# Display the count dataframe
head(count_fig_df)
# Create subset_edge_df with attribute_values starting with "https"
pmc_df <- edges_df %>%
filter(grepl("^PMCID", attribute_value))
# Display the final dataframe
head(pmc_df)
# Count the unique values in attribute_value_2
count_pmc_df <- pmc_df %>%
group_by(attribute_value) %>%
summarise(count = n()) %>%
arrange(desc(count)) %>%
as.data.frame()
# Display the count dataframe
head(count_pmc_df)
# URL of the JSON file
url <- "https://bte.transltr.io/v1/asyncquery_response/dOxPBtuAYs"
# Retrieve JSON file from the URL
response <- GET(url)
json_data <- content(response, as = "text")
parsed_data <- fromJSON(json_data, flatten = TRUE)
# Extract relevant entries
edges <- parsed_data$message$knowledge_graph$edges
# Initialize an empty list to store the results
results <- list()
# Iterate over each edge by index
for (i in seq_along(edges)) {
edge <- edges[[i]]
predicate <- edge$predicate
subject <- edge$subject
object <- edge$object
# Only include cases where predicate is "biolink:occurs_together_in_literature_with"
if (predicate == "biolink:occurs_together_in_literature_with") {
# Check if attributes exist and if the first attribute has a value
if (!is.null(edge$attributes) && length(edge$attributes) > 0) {
first_attr <- edge$attributes[1,]
if (!is.null(first_attr$value)) {
if (is.atomic(first_attr$value)) {
first_attribute_values <- list(first_attr$value)
} else if (is.list(first_attr$value) && length(first_attr$value) > 0) {
first_attribute_values <- first_attr$value[[1]]
} else {
first_attribute_values <- NA
}
}
# Create a separate row for each value in first_attr$value[[1]]
for (value in first_attribute_values) {
results[[length(results) + 1]] <- data.frame(
predicate = predicate,
subject = subject,
object = object,
attribute_value = value,
stringsAsFactors = FALSE
)
}
}
}
}
# Combine the list into a single dataframe
edges_df <- bind_rows(results)
# Display the dataframe
head(edges_df)
# Create subset_edge_df with attribute_values starting with "https"
fig_df <- edges_df %>%
filter(grepl("^https", attribute_value))
# Display the final dataframe
head(fig_df)
# Count the unique values in attribute_value_2
count_fig_df <- fig_df %>%
group_by(attribute_value) %>%
summarise(count = n()) %>%
arrange(desc(count)) %>%
as.data.frame()
# Display the count dataframe
head(count_fig_df)
# Create subset_edge_df with attribute_values starting with "https"
pmc_df <- edges_df %>%
filter(grepl("^PMCID", attribute_value))
# Display the final dataframe
head(pmc_df)
# Count the unique values in attribute_value_2
count_pmc_df <- pmc_df %>%
group_by(attribute_value) %>%
summarise(count = n()) %>%
arrange(desc(count)) %>%
as.data.frame()
# Display the count dataframe
head(count_pmc_df)
# URL of the JSON file
url <- "https://bte.transltr.io/v1/asyncquery_response/wHcXAVsGg9"
# Retrieve JSON file from the URL
response <- GET(url)
json_data <- content(response, as = "text")
parsed_data <- fromJSON(json_data, flatten = TRUE)
# Extract relevant entries
edges <- parsed_data$message$knowledge_graph$edges
# Initialize an empty list to store the results
results <- list()
# Iterate over each edge by index
for (i in seq_along(edges)) {
edge <- edges[[i]]
predicate <- edge$predicate
subject <- edge$subject
object <- edge$object
# Only include cases where predicate is "biolink:occurs_together_in_literature_with"
if (predicate == "biolink:occurs_together_in_literature_with") {
# Check if attributes exist and if the first attribute has a value
if (!is.null(edge$attributes) && length(edge$attributes) > 0) {
first_attr <- edge$attributes[1,]
if (!is.null(first_attr$value)) {
if (is.atomic(first_attr$value)) {
first_attribute_values <- list(first_attr$value)
} else if (is.list(first_attr$value) && length(first_attr$value) > 0) {
first_attribute_values <- first_attr$value[[1]]
} else {
first_attribute_values <- NA
}
}
# Create a separate row for each value in first_attr$value[[1]]
for (value in first_attribute_values) {
results[[length(results) + 1]] <- data.frame(
predicate = predicate,
subject = subject,
object = object,
attribute_value = value,
stringsAsFactors = FALSE
)
}
}
}
}
# Combine the list into a single dataframe
edges_df <- bind_rows(results)
# Display the dataframe
head(edges_df)
# Create subset_edge_df with attribute_values starting with "https"
fig_df <- edges_df %>%
filter(grepl("^https", attribute_value))
# Display the final dataframe
head(fig_df)
# Count the unique values in attribute_value_2
count_fig_df <- fig_df %>%
group_by(attribute_value) %>%
summarise(count = n()) %>%
arrange(desc(count)) %>%
as.data.frame()
# Display the count dataframe
head(count_fig_df)
# Create subset_edge_df with attribute_values starting with "https"
pmc_df <- edges_df %>%
filter(grepl("^PMCID", attribute_value))
# Display the final dataframe
head(pmc_df)
# Count the unique values in attribute_value_2
count_pmc_df <- pmc_df %>%
group_by(attribute_value) %>%
summarise(count = n()) %>%
arrange(desc(count)) %>%
as.data.frame()
# Display the count dataframe
head(count_pmc_df)
# URL of the JSON file
url <- "https://bte.transltr.io/v1/asyncquery_response/1fpGPHB2TH"
# Retrieve JSON file from the URL
response <- GET(url)
json_data <- content(response, as = "text")
parsed_data <- fromJSON(json_data, flatten = TRUE)
# Extract relevant entries
edges <- parsed_data$message$knowledge_graph$edges
# Initialize an empty list to store the results
results <- list()
# Iterate over each edge by index
for (i in seq_along(edges)) {
edge <- edges[[i]]
predicate <- edge$predicate
subject <- edge$subject
object <- edge$object
# Only include cases where predicate is "biolink:occurs_together_in_literature_with"
if (predicate == "biolink:occurs_together_in_literature_with") {
# Check if attributes exist and if the first attribute has a value
if (!is.null(edge$attributes) && length(edge$attributes) > 0) {
first_attr <- edge$attributes[1,]
if (!is.null(first_attr$value)) {
if (is.atomic(first_attr$value)) {
first_attribute_values <- list(first_attr$value)
} else if (is.list(first_attr$value) && length(first_attr$value) > 0) {
first_attribute_values <- first_attr$value[[1]]
} else {
first_attribute_values <- NA
}
}
# Create a separate row for each value in first_attr$value[[1]]
for (value in first_attribute_values) {
results[[length(results) + 1]] <- data.frame(
predicate = predicate,
subject = subject,
object = object,
attribute_value = value,
stringsAsFactors = FALSE
)
}
}
}
}
# Combine the list into a single dataframe
edges_df <- bind_rows(results)
# Display the dataframe
head(edges_df)
# Create subset_edge_df with attribute_values starting with "https"
fig_df <- edges_df %>%
filter(grepl("^https", attribute_value))
# Display the final dataframe
head(fig_df)
# Count the unique values in attribute_value_2
count_fig_df <- fig_df %>%
group_by(attribute_value) %>%
summarise(count = n()) %>%
arrange(desc(count)) %>%
as.data.frame()
# Display the count dataframe
head(count_fig_df)
# Create subset_edge_df with attribute_values starting with "https"
pmc_df <- edges_df %>%
filter(grepl("^PMCID", attribute_value))
# Display the final dataframe
head(pmc_df)
# Count the unique values in attribute_value_2
count_pmc_df <- pmc_df %>%
group_by(attribute_value) %>%
summarise(count = n()) %>%
arrange(desc(count)) %>%
as.data.frame()
# Display the count dataframe
head(count_pmc_df)
